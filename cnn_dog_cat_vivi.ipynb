{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dog_cat_data removed\n",
      "folders created !\n",
      "Data copied!\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './cnn_model_2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa0b6339c88>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "predictions: {'classes': <tf.Tensor 'ArgMax:0' shape=(?,) dtype=int64>, 'probabilities': <tf.Tensor 'softmax_tensor:0' shape=(?, 2) dtype=float32>}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./cnn_model_2/model.ckpt-5001\n",
      "INFO:tensorflow:Saving checkpoints for 5002 into ./cnn_model_2/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.301352, step = 5002\n",
      "INFO:tensorflow:global_step/sec: 6.34848\n",
      "INFO:tensorflow:loss = 0.360414, step = 5102 (15.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.22833\n",
      "INFO:tensorflow:loss = 0.347614, step = 5202 (16.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.26514\n",
      "INFO:tensorflow:loss = 0.421389, step = 5302 (15.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.27493\n",
      "INFO:tensorflow:loss = 0.350386, step = 5402 (15.937 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.22717\n",
      "INFO:tensorflow:loss = 0.310788, step = 5502 (16.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20003\n",
      "INFO:tensorflow:loss = 0.465119, step = 5602 (16.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20575\n",
      "INFO:tensorflow:loss = 0.362676, step = 5702 (16.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.28477\n",
      "INFO:tensorflow:loss = 0.237382, step = 5802 (15.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.16584\n",
      "INFO:tensorflow:loss = 0.369484, step = 5902 (16.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20174\n",
      "INFO:tensorflow:loss = 0.308474, step = 6002 (16.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.27395\n",
      "INFO:tensorflow:loss = 0.327122, step = 6102 (15.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.26189\n",
      "INFO:tensorflow:loss = 0.283088, step = 6202 (15.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.23665\n",
      "INFO:tensorflow:loss = 0.357048, step = 6302 (16.034 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.14324\n",
      "INFO:tensorflow:loss = 0.203947, step = 6402 (16.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.24876\n",
      "INFO:tensorflow:loss = 0.26348, step = 6502 (16.003 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.26902\n",
      "INFO:tensorflow:loss = 0.280748, step = 6602 (15.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.25807\n",
      "INFO:tensorflow:loss = 0.266168, step = 6702 (15.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.33635\n",
      "INFO:tensorflow:loss = 0.277708, step = 6802 (15.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.37346\n",
      "INFO:tensorflow:loss = 0.207785, step = 6902 (15.690 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.58702\n",
      "INFO:tensorflow:loss = 0.27287, step = 7002 (15.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.38816\n",
      "INFO:tensorflow:loss = 0.343592, step = 7102 (15.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.39929\n",
      "INFO:tensorflow:loss = 0.275436, step = 7202 (15.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.39454\n",
      "INFO:tensorflow:loss = 0.382797, step = 7302 (15.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.4395\n",
      "INFO:tensorflow:loss = 0.246007, step = 7402 (15.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.35464\n",
      "INFO:tensorflow:loss = 0.288219, step = 7502 (15.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.405\n",
      "INFO:tensorflow:loss = 0.271757, step = 7602 (15.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.44376\n",
      "INFO:tensorflow:loss = 0.254816, step = 7702 (15.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.45286\n",
      "INFO:tensorflow:loss = 0.238445, step = 7802 (15.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.37002\n",
      "INFO:tensorflow:loss = 0.230735, step = 7902 (15.699 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8001 into ./cnn_model_2/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.192133.\n",
      "train_result: <tensorflow.python.estimator.estimator.Estimator object at 0x7fa0b5ee4828>\n",
      "predictions: {'classes': <tf.Tensor 'ArgMax:0' shape=(?,) dtype=int64>, 'probabilities': <tf.Tensor 'softmax_tensor:0' shape=(?, 2) dtype=float32>}\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-04-06:05:07\n",
      "INFO:tensorflow:Restoring parameters from ./cnn_model_2/model.ckpt-8001\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-04-06:05:18\n",
      "INFO:tensorflow:Saving dict for global step 8001: accuracy = 0.8544, global_step = 8001, loss = 0.332052\n",
      "eval_results: {'accuracy': 0.85439998, 'loss': 0.33205214, 'global_step': 8001}\n",
      "----------ALL Done!----------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "#%%\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' #use GPU with ID=0\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5 # maximun alloc gpu50% of MEM\n",
    "config.gpu_options.allow_growth = True #allocate dynamically\n",
    "sess = tf.Session(config = config)\n",
    "\n",
    "def organize_datasets(src_train_path, dest_train_path, n= 25000, ratio=0.2):\n",
    "    src_path = pathlib.Path(src_train_path)\n",
    "    # get all jpg files in this src_path path \n",
    "    files = list(src_path.glob('*.jpg'))\n",
    "    random.shuffle(files)    \n",
    "    files = files[:n]\n",
    "    \n",
    "    n = int(len(files) * ratio)\n",
    "    val, train = files[:n], files[n:]\n",
    "   \n",
    "    # remove old training folders\n",
    "    shutil.rmtree(dest_train_path, True) \n",
    "    print('{} removed'.format(dest_train_path))\n",
    "    \n",
    "    # create new training folders\n",
    "    for c in ['dogs', 'cats']: \n",
    "        os.makedirs('{}/train/{}/'.format(dest_train_path, c))\n",
    "        os.makedirs('{}/validation/{}/'.format(dest_train_path, c))\n",
    "    print('folders created !')\n",
    "\n",
    "    # determine the picture's name is cat or dog\n",
    "    for t in train:\n",
    "        if 'cat' in t.name:\n",
    "            shutil.copy2(t, os.path.join(dest_train_path, 'train', 'cats'))\n",
    "        else:\n",
    "            shutil.copy2(t, os.path.join(dest_train_path, 'train', 'dogs'))\n",
    "                \n",
    "    for v in val:\n",
    "        if 'cat' in v.name:\n",
    "            shutil.copy2(v, os.path.join(dest_train_path, 'validation', 'cats'))\n",
    "        else:\n",
    "            shutil.copy2(v, os.path.join(dest_train_path, 'validation', 'dogs'))\n",
    "    print('Data copied!')    \n",
    "    \n",
    "src_train = './dog_cat/train'\n",
    "training_path = './dog_cat_data'\n",
    "organize_datasets(src_train, training_path)\n",
    "\n",
    "#%%\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    input_layer = tf.reshape(features, [-1, 150, 150, 3])\n",
    "    \n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "            inputs=input_layer,\n",
    "            filters=32,\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "        \n",
    "    # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "        \n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "            inputs=pool1,\n",
    "            filters=64,\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "       \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    # Dense Layer\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 37 * 37 * 64])\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dropout, units=2)\n",
    "\n",
    "    predictions = {\n",
    "            # Generate predictions (for PREDICT and EVAL mode)\n",
    "            \"classes\": tf.argmax(input=logits, axis=1),\n",
    "            # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "            # `logging_hook`.\n",
    "            \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "            }    \n",
    "    print('predictions:', predictions)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=2)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "            onehot_labels=onehot_labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        starter_learning_rate = 0.001\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        learning_rate = tf.train.exponential_decay(starter_learning_rate,\n",
    "                                                   global_step,\n",
    "                                                   decay_steps=500,\n",
    "                                                   decay_rate=0.9,\n",
    "                                                   staircase=True)\n",
    "        optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
    "        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])}\n",
    "            \n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)    \n",
    "\n",
    "#%% \n",
    "\n",
    "def get_files(dogs, cats):        \n",
    "    dogs_path = pathlib.Path(dogs)\n",
    "    cats_path = pathlib.Path(cats)\n",
    "    \n",
    "    dogs_list = list(dogs_path.glob('*.jpg'))\n",
    "    cats_list = list(cats_path.glob('*.jpg'))\n",
    "    file_list_add = dogs_list + cats_list\n",
    "    random.shuffle(file_list_add)\n",
    "    file_list = [str(i) for i in file_list_add]  \n",
    "    \n",
    "    label_list = []\n",
    "    for t in file_list_add:\n",
    "        if 'cat' in t.name:\n",
    "            label_list.append(0) \n",
    "        else:\n",
    "            label_list.append(1) \n",
    "    \n",
    "    return file_list, label_list\n",
    "\n",
    "dogs_train = './dog_cat_data/train/dogs'\n",
    "cats_train = './dog_cat_data/train/cats'\n",
    "train_file_list, train_label_list = get_files(dogs_train, cats_train)\n",
    "\n",
    "dogs_validation = './dog_cat_data/validation/dogs'\n",
    "cats_validation = './dog_cat_data/validation/cats'\n",
    "validation_file_list, validation_label_list = get_files(dogs_validation, cats_validation)\n",
    "\n",
    "def _parse_function(filename, label):\n",
    "    image_H = image_W = 150\n",
    "    image_string = tf.read_file(filename)\n",
    "    image_decoded = tf.image.decode_jpeg(image_string)  \n",
    "    image_resized = tf.image.resize_images(image_decoded, [image_H, image_W])\n",
    "    img_std = tf.image.per_image_standardization(image_resized)\n",
    "    return img_std, label\n",
    "\n",
    "#%%\n",
    "batch_size = 50\n",
    "\n",
    "def train_input_fn():\n",
    "    '''\n",
    "    運行dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))後，dataset的一個元素是(filename, label)。\n",
    "    filename是圖片的文件名，label是圖片對應的標籤。\n",
    "    \n",
    "    之後通過map，將filename對應的圖片讀入，並縮放為150x150的大小。此時dataset中的一個元素是(image_resized, label)。    \n",
    "    dataset.shuffle(buffersize=1000).batch(32).repeat()的功能是：在每個epoch內將圖片打亂組成大小為32的batch，無限重複。\n",
    "    \n",
    "    最後，dataset中的一個元素是(image_std_batch, label_batch)\n",
    "    image_std_batch(32, 150, 150, 3)，而label_batch的形狀為(32, )，接下來我們就可以用這兩個Tensor來建立模型了。\n",
    "    \n",
    "    '''\n",
    "    global train_file_list\n",
    "    global train_label_list\n",
    "    global num_epochs\n",
    "    global batch_size    \n",
    "    \n",
    "    filenames = tf.constant(train_file_list)\n",
    "    train_lables = tf.constant(train_label_list)   \n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames , train_lables))\n",
    "    dataset = dataset.map(_parse_function)\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    \n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(batch_size)\n",
    "        \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features, labels = iterator.get_next()\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "def validation_input_fn():\n",
    "    global validation_file_list\n",
    "    global validation_label_list\n",
    "    global num_epochs\n",
    "    global batch_size\n",
    "    \n",
    "    filenames = tf.constant(validation_file_list)\n",
    "    validation_lables = tf.constant(validation_label_list)\n",
    "   \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames , validation_lables))\n",
    "    dataset = dataset.map(_parse_function)\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    \n",
    "    #dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(batch_size)\n",
    " \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    validation, v_lables = iterator.get_next() \n",
    "    \n",
    "    return validation, v_lables\n",
    "\n",
    "\n",
    "#%% Get training and eval data\n",
    "\n",
    "# Create the Estimator\n",
    "dog_cat_classifier = tf.estimator.Estimator( model_fn=cnn_model_fn, model_dir=\"./cnn_model_2\")\n",
    "\n",
    "# Set up logging for predictions\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=50)\n",
    "  \n",
    "# Train the model\n",
    "#train_result = dog_cat_classifier.train( input_fn=train_input_fn, steps=3000, hooks=[logging_hook])\n",
    "train_result = dog_cat_classifier.train( input_fn=train_input_fn, steps=3000)\n",
    "print('train_result:', train_result)\n",
    "\n",
    "# Evaluate the model and print results\n",
    "#eval_results = dog_cat_classifier.evaluate(input_fn=validation_input_fn, steps=100)\n",
    "eval_results = dog_cat_classifier.evaluate(input_fn=validation_input_fn)\n",
    "print('eval_results:', eval_results)  \n",
    "print('----------ALL Done!----------')\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
